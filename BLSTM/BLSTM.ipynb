{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "# imports\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sequences and labels from disk\n",
    "# sequences = np.load('../sequences.npy')\n",
    "# labels = np.load('../labels.npy')\n",
    "################!!!!!!!!!!!!!!!!!!!!! they are now nparrays instead of lists, so no need to convert them to nparrays again in the code below\n",
    "\n",
    "sequences = np.load('../sequences_augmented.npy')\n",
    "labels = np.load('../labels_augmented.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences\n",
    "y= to_categorical(labels).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - accuracy: 0.0366 - loss: 4.0802 - val_accuracy: 0.1248 - val_loss: 3.3908\n",
      "Epoch 2/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.1458 - loss: 3.2211 - val_accuracy: 0.2017 - val_loss: 2.8298\n",
      "Epoch 3/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.2816 - loss: 2.4994 - val_accuracy: 0.3632 - val_loss: 2.1626\n",
      "Epoch 4/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.4112 - loss: 1.9432 - val_accuracy: 0.5325 - val_loss: 1.5224\n",
      "Epoch 5/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.6030 - loss: 1.2969 - val_accuracy: 0.6829 - val_loss: 1.0706\n",
      "Epoch 6/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.6922 - loss: 0.9756 - val_accuracy: 0.7256 - val_loss: 0.8426\n",
      "Epoch 7/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - accuracy: 0.7749 - loss: 0.7214 - val_accuracy: 0.6675 - val_loss: 1.0707\n",
      "Epoch 8/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 101ms/step - accuracy: 0.7754 - loss: 0.6842 - val_accuracy: 0.8000 - val_loss: 0.6188\n",
      "Epoch 9/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - accuracy: 0.8386 - loss: 0.5025 - val_accuracy: 0.8453 - val_loss: 0.4988\n",
      "Epoch 10/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 101ms/step - accuracy: 0.8617 - loss: 0.4196 - val_accuracy: 0.8547 - val_loss: 0.4673\n",
      "Epoch 11/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 99ms/step - accuracy: 0.8877 - loss: 0.3386 - val_accuracy: 0.8479 - val_loss: 0.4750\n",
      "Epoch 12/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - accuracy: 0.8878 - loss: 0.3318 - val_accuracy: 0.7667 - val_loss: 0.7660\n",
      "Epoch 13/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 107ms/step - accuracy: 0.8788 - loss: 0.3555 - val_accuracy: 0.8650 - val_loss: 0.4393\n",
      "Epoch 14/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - accuracy: 0.9147 - loss: 0.2587 - val_accuracy: 0.8709 - val_loss: 0.3937\n",
      "Epoch 15/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 102ms/step - accuracy: 0.8979 - loss: 0.2972 - val_accuracy: 0.8940 - val_loss: 0.3386\n",
      "Epoch 16/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - accuracy: 0.9232 - loss: 0.2301 - val_accuracy: 0.8658 - val_loss: 0.3900\n",
      "Epoch 17/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 99ms/step - accuracy: 0.9421 - loss: 0.1770 - val_accuracy: 0.8889 - val_loss: 0.3490\n",
      "Epoch 18/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.9502 - loss: 0.1634 - val_accuracy: 0.8880 - val_loss: 0.3446\n",
      "Epoch 19/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.9588 - loss: 0.1313 - val_accuracy: 0.8709 - val_loss: 0.4028\n",
      "Epoch 20/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.9481 - loss: 0.1523 - val_accuracy: 0.8786 - val_loss: 0.3795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1723ced08d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Define the model\n",
    "model_blstm = Sequential(name='model_blstm')\n",
    "model_blstm.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(30, 1662)))\n",
    "model_blstm.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model_blstm.add(Bidirectional(LSTM(128)))\n",
    "model_blstm.add(Dense(65, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_blstm.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_blstm.fit(X_train, y_train, epochs=100, callbacks=[tb_callback, early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 104ms/step - accuracy: 0.0121 - loss: 4.1895 - val_accuracy: 0.0103 - val_loss: 4.1756\n",
      "Epoch 2/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0157 - loss: 4.1741 - val_accuracy: 0.0068 - val_loss: 4.1767\n",
      "Epoch 3/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - accuracy: 0.0128 - loss: 4.1737 - val_accuracy: 0.0068 - val_loss: 4.1777\n",
      "Epoch 4/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.0148 - loss: 4.1737 - val_accuracy: 0.0103 - val_loss: 4.1785\n",
      "Epoch 5/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - accuracy: 0.0195 - loss: 4.1738 - val_accuracy: 0.0103 - val_loss: 4.1794\n",
      "Epoch 6/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.0190 - loss: 4.1730 - val_accuracy: 0.0103 - val_loss: 4.1802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17210011990>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Define the model\n",
    "model_blstm_2 = Sequential()\n",
    "model_blstm_2.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(30, 1662)))\n",
    "model_blstm_2.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model_blstm_2.add(Bidirectional(LSTM(128)))\n",
    "model_blstm_2.add(Dense(65, activation='relu'))\n",
    "model_blstm_2.add(Dense(65, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_blstm_2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_blstm_2.fit(X_train, y_train, epochs=100, callbacks=[tb_callback, early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 99ms/step - accuracy: 0.0140 - loss: 9.0912 - val_accuracy: 0.0154 - val_loss: 8.6411\n",
      "Epoch 2/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0154 - loss: 8.5469 - val_accuracy: 0.0154 - val_loss: 8.6261\n",
      "Epoch 3/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.0176 - loss: 8.6788 - val_accuracy: 0.0154 - val_loss: 8.6216\n",
      "Epoch 4/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0148 - loss: 8.6207 - val_accuracy: 0.0154 - val_loss: 8.6160\n",
      "Epoch 5/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0115 - loss: 8.5512 - val_accuracy: 0.0154 - val_loss: 8.6186\n",
      "Epoch 6/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.0156 - loss: 8.7804 - val_accuracy: 0.0137 - val_loss: 8.6148\n",
      "Epoch 7/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - accuracy: 0.0197 - loss: 8.5604 - val_accuracy: 0.0316 - val_loss: 8.6083\n",
      "Epoch 8/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0306 - loss: 8.6355 - val_accuracy: 0.0248 - val_loss: 8.5698\n",
      "Epoch 9/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0261 - loss: 8.6963 - val_accuracy: 0.0291 - val_loss: 8.5305\n",
      "Epoch 10/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - accuracy: 0.0404 - loss: 8.4983 - val_accuracy: 0.0521 - val_loss: 8.5351\n",
      "Epoch 11/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.0525 - loss: 8.6150 - val_accuracy: 0.0530 - val_loss: 8.3966\n",
      "Epoch 12/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.0511 - loss: 8.6202 - val_accuracy: 0.0239 - val_loss: 8.7215\n",
      "Epoch 13/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 99ms/step - accuracy: 0.0294 - loss: 8.7197 - val_accuracy: 0.0410 - val_loss: 8.4326\n",
      "Epoch 14/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 98ms/step - accuracy: 0.0328 - loss: 8.6924 - val_accuracy: 0.0137 - val_loss: 8.6447\n",
      "Epoch 15/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 100ms/step - accuracy: 0.0134 - loss: 8.6004 - val_accuracy: 0.0137 - val_loss: 8.6190\n",
      "Epoch 16/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 105ms/step - accuracy: 0.0166 - loss: 8.7064 - val_accuracy: 0.0137 - val_loss: 8.5845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x172291fa050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Define the model\n",
    "model_blstm_3 = Sequential()\n",
    "model_blstm_3.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(30, 1662)))\n",
    "model_blstm_3.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model_blstm_3.add(Bidirectional(LSTM(128)))\n",
    "model_blstm_3.add(Dense(65, activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_blstm_3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_blstm_3.fit(X_train, y_train, epochs=100, callbacks=[tb_callback, early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.0172 - loss: 4.1742 - val_accuracy: 0.0205 - val_loss: 4.1235\n",
      "Epoch 2/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - accuracy: 0.0431 - loss: 4.0833 - val_accuracy: 0.0316 - val_loss: 3.9859\n",
      "Epoch 3/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - accuracy: 0.0569 - loss: 3.9155 - val_accuracy: 0.0538 - val_loss: 3.8115\n",
      "Epoch 4/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - accuracy: 0.0675 - loss: 3.7562 - val_accuracy: 0.0769 - val_loss: 3.6271\n",
      "Epoch 5/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 87ms/step - accuracy: 0.1072 - loss: 3.5878 - val_accuracy: 0.1188 - val_loss: 3.4951\n",
      "Epoch 6/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 88ms/step - accuracy: 0.1556 - loss: 3.4209 - val_accuracy: 0.1308 - val_loss: 3.3235\n",
      "Epoch 7/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 101ms/step - accuracy: 0.1796 - loss: 3.2907 - val_accuracy: 0.1085 - val_loss: 3.5175\n",
      "Epoch 8/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.2163 - loss: 3.1957 - val_accuracy: 0.1761 - val_loss: 3.1004\n",
      "Epoch 9/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.2436 - loss: 3.0115 - val_accuracy: 0.2641 - val_loss: 2.9149\n",
      "Epoch 10/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - accuracy: 0.2751 - loss: 2.8766 - val_accuracy: 0.2735 - val_loss: 2.7699\n",
      "Epoch 11/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 89ms/step - accuracy: 0.3150 - loss: 2.6955 - val_accuracy: 0.3385 - val_loss: 2.6597\n",
      "Epoch 12/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 89ms/step - accuracy: 0.3206 - loss: 2.6135 - val_accuracy: 0.2855 - val_loss: 2.5897\n",
      "Epoch 13/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 88ms/step - accuracy: 0.3728 - loss: 2.4254 - val_accuracy: 0.1872 - val_loss: 2.8372\n",
      "Epoch 14/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.3818 - loss: 2.3241 - val_accuracy: 0.3103 - val_loss: 2.4521\n",
      "Epoch 15/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.4140 - loss: 2.1872 - val_accuracy: 0.3444 - val_loss: 2.3628\n",
      "Epoch 16/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.4470 - loss: 2.0651 - val_accuracy: 0.2949 - val_loss: 2.5521\n",
      "Epoch 17/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.4494 - loss: 1.9998 - val_accuracy: 0.4077 - val_loss: 2.0888\n",
      "Epoch 18/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.4719 - loss: 1.8757 - val_accuracy: 0.3188 - val_loss: 2.3656\n",
      "Epoch 19/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.4882 - loss: 1.8451 - val_accuracy: 0.4752 - val_loss: 1.7908\n",
      "Epoch 20/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.5347 - loss: 1.6508 - val_accuracy: 0.3214 - val_loss: 2.5325\n",
      "Epoch 21/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.5586 - loss: 1.5924 - val_accuracy: 0.3632 - val_loss: 2.1589\n",
      "Epoch 22/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 91ms/step - accuracy: 0.5681 - loss: 1.5092 - val_accuracy: 0.6000 - val_loss: 1.3971\n",
      "Epoch 23/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 88ms/step - accuracy: 0.6011 - loss: 1.3906 - val_accuracy: 0.1479 - val_loss: 3.3119\n",
      "Epoch 24/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - accuracy: 0.6121 - loss: 1.3841 - val_accuracy: 0.4812 - val_loss: 1.7354\n",
      "Epoch 25/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 86ms/step - accuracy: 0.6647 - loss: 1.1871 - val_accuracy: 0.4915 - val_loss: 1.7166\n",
      "Epoch 26/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 87ms/step - accuracy: 0.6536 - loss: 1.1689 - val_accuracy: 0.3197 - val_loss: 2.5906\n",
      "Epoch 27/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 88ms/step - accuracy: 0.6562 - loss: 1.2007 - val_accuracy: 0.5564 - val_loss: 1.4480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1723165cc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Define the model\n",
    "model_blstm_4 = Sequential()\n",
    "model_blstm_4.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(30, 1662)))\n",
    "model_blstm_4.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model_blstm_4.add(Bidirectional(LSTM(128)))\n",
    "model_blstm_4.add(Dense(65, activation='softmax'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_blstm_4.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_blstm_4.fit(X_train, y_train, epochs=100, callbacks=[tb_callback, early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.0328 - loss: 4.1056 - val_accuracy: 0.0769 - val_loss: 3.5540\n",
      "Epoch 2/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.0810 - loss: 3.5392 - val_accuracy: 0.1316 - val_loss: 3.2047\n",
      "Epoch 3/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.1356 - loss: 3.1750 - val_accuracy: 0.2085 - val_loss: 2.8718\n",
      "Epoch 4/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.2393 - loss: 2.7391 - val_accuracy: 0.2299 - val_loss: 2.7512\n",
      "Epoch 5/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.3045 - loss: 2.4323 - val_accuracy: 0.3949 - val_loss: 2.1373\n",
      "Epoch 6/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.3947 - loss: 2.0692 - val_accuracy: 0.4590 - val_loss: 1.8843\n",
      "Epoch 7/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.4825 - loss: 1.7343 - val_accuracy: 0.4906 - val_loss: 1.7243\n",
      "Epoch 8/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.5555 - loss: 1.4838 - val_accuracy: 0.5000 - val_loss: 1.6364\n",
      "Epoch 9/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.6070 - loss: 1.3189 - val_accuracy: 0.6462 - val_loss: 1.1614\n",
      "Epoch 10/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.6908 - loss: 1.0139 - val_accuracy: 0.6333 - val_loss: 1.1262\n",
      "Epoch 11/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.7120 - loss: 0.9314 - val_accuracy: 0.7325 - val_loss: 0.8665\n",
      "Epoch 12/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.7695 - loss: 0.7556 - val_accuracy: 0.7350 - val_loss: 0.8510\n",
      "Epoch 13/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.7798 - loss: 0.6853 - val_accuracy: 0.7761 - val_loss: 0.7205\n",
      "Epoch 14/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8267 - loss: 0.5634 - val_accuracy: 0.7846 - val_loss: 0.6990\n",
      "Epoch 15/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8354 - loss: 0.5359 - val_accuracy: 0.7974 - val_loss: 0.6549\n",
      "Epoch 16/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.8484 - loss: 0.4677 - val_accuracy: 0.7735 - val_loss: 0.7134\n",
      "Epoch 17/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.8607 - loss: 0.4403 - val_accuracy: 0.8231 - val_loss: 0.5716\n",
      "Epoch 18/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.9000 - loss: 0.3325 - val_accuracy: 0.8376 - val_loss: 0.4916\n",
      "Epoch 19/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.8864 - loss: 0.3660 - val_accuracy: 0.7479 - val_loss: 0.8172\n",
      "Epoch 20/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.8848 - loss: 0.3331 - val_accuracy: 0.8197 - val_loss: 0.5534\n",
      "Epoch 21/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.9059 - loss: 0.3117 - val_accuracy: 0.8154 - val_loss: 0.5852\n",
      "Epoch 22/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.9117 - loss: 0.2916 - val_accuracy: 0.7513 - val_loss: 0.8199\n",
      "Epoch 23/100\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.8914 - loss: 0.3246 - val_accuracy: 0.8282 - val_loss: 0.5294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17245449990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Define the model\n",
    "model_blstm_5 = Sequential(name='model_blstm')\n",
    "model_blstm_5.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(30, 1662)))\n",
    "model_blstm_5.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model_blstm_5.add(Bidirectional(LSTM(64)))\n",
    "model_blstm_5.add(Dense(65, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_blstm_5.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_blstm_5.fit(X_train, y_train, epochs=100, callbacks=[tb_callback, early_stopping], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    }
   ],
   "source": [
    "results_blstm = model_blstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as models\n",
    "\n",
    "\n",
    "model_blstm.save('../actions_blstm.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_blstm.load_weights('../actions/actions_blstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.8769230769230769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[636,   0],\n",
       "        [  5,   9]],\n",
       "\n",
       "       [[628,  12],\n",
       "        [  2,   8]],\n",
       "\n",
       "       [[633,   1],\n",
       "        [ 13,   3]],\n",
       "\n",
       "       [[637,   0],\n",
       "        [  0,  13]],\n",
       "\n",
       "       [[635,   2],\n",
       "        [  4,   9]],\n",
       "\n",
       "       [[638,   1],\n",
       "        [  0,  11]],\n",
       "\n",
       "       [[640,   3],\n",
       "        [  2,   5]],\n",
       "\n",
       "       [[638,   3],\n",
       "        [  0,   9]],\n",
       "\n",
       "       [[642,   2],\n",
       "        [  2,   4]],\n",
       "\n",
       "       [[646,   0],\n",
       "        [  2,   2]],\n",
       "\n",
       "       [[637,   2],\n",
       "        [  3,   8]],\n",
       "\n",
       "       [[639,   3],\n",
       "        [  5,   3]],\n",
       "\n",
       "       [[642,   0],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[638,   0],\n",
       "        [  2,  10]],\n",
       "\n",
       "       [[637,   2],\n",
       "        [  0,  11]],\n",
       "\n",
       "       [[639,   1],\n",
       "        [  1,   9]],\n",
       "\n",
       "       [[639,   0],\n",
       "        [  1,  10]],\n",
       "\n",
       "       [[637,   3],\n",
       "        [  2,   8]],\n",
       "\n",
       "       [[637,   2],\n",
       "        [  0,  11]],\n",
       "\n",
       "       [[645,   0],\n",
       "        [  1,   4]],\n",
       "\n",
       "       [[642,   1],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[641,   0],\n",
       "        [  1,   8]],\n",
       "\n",
       "       [[642,   1],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[640,   0],\n",
       "        [  1,   9]],\n",
       "\n",
       "       [[638,   3],\n",
       "        [  1,   8]],\n",
       "\n",
       "       [[637,   2],\n",
       "        [  0,  11]],\n",
       "\n",
       "       [[639,   0],\n",
       "        [  1,  10]],\n",
       "\n",
       "       [[639,   3],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[639,   1],\n",
       "        [  0,  10]],\n",
       "\n",
       "       [[635,   1],\n",
       "        [  7,   7]],\n",
       "\n",
       "       [[638,   0],\n",
       "        [  0,  12]],\n",
       "\n",
       "       [[634,   0],\n",
       "        [  0,  16]],\n",
       "\n",
       "       [[636,   0],\n",
       "        [  4,  10]],\n",
       "\n",
       "       [[636,   0],\n",
       "        [  0,  14]],\n",
       "\n",
       "       [[640,   0],\n",
       "        [  0,  10]],\n",
       "\n",
       "       [[647,   0],\n",
       "        [  0,   3]],\n",
       "\n",
       "       [[642,   1],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[641,   0],\n",
       "        [  0,   9]],\n",
       "\n",
       "       [[629,   7],\n",
       "        [  2,  12]],\n",
       "\n",
       "       [[638,   2],\n",
       "        [  0,  10]],\n",
       "\n",
       "       [[640,   2],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[638,   5],\n",
       "        [  1,   6]],\n",
       "\n",
       "       [[641,   1],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[638,   0],\n",
       "        [  0,  12]],\n",
       "\n",
       "       [[641,   0],\n",
       "        [  0,   9]],\n",
       "\n",
       "       [[642,   1],\n",
       "        [  0,   7]],\n",
       "\n",
       "       [[640,   0],\n",
       "        [  2,   8]],\n",
       "\n",
       "       [[642,   0],\n",
       "        [  2,   6]],\n",
       "\n",
       "       [[645,   0],\n",
       "        [  0,   5]],\n",
       "\n",
       "       [[638,   1],\n",
       "        [  0,  11]],\n",
       "\n",
       "       [[637,   0],\n",
       "        [  0,  13]],\n",
       "\n",
       "       [[640,   2],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[642,   0],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[635,   1],\n",
       "        [  3,  11]],\n",
       "\n",
       "       [[636,   0],\n",
       "        [  1,  13]],\n",
       "\n",
       "       [[644,   0],\n",
       "        [  0,   6]],\n",
       "\n",
       "       [[638,   0],\n",
       "        [  1,  11]],\n",
       "\n",
       "       [[637,   0],\n",
       "        [  0,  13]],\n",
       "\n",
       "       [[643,   2],\n",
       "        [  1,   4]],\n",
       "\n",
       "       [[640,   0],\n",
       "        [  0,  10]],\n",
       "\n",
       "       [[636,   0],\n",
       "        [  1,  13]],\n",
       "\n",
       "       [[630,   5],\n",
       "        [  1,  14]],\n",
       "\n",
       "       [[641,   1],\n",
       "        [  0,   8]],\n",
       "\n",
       "       [[640,   0],\n",
       "        [  5,   5]],\n",
       "\n",
       "       [[640,   0],\n",
       "        [  0,  10]]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "y_pred_blstm = model_blstm.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "ypred_blstm = np.argmax(y_pred_blstm, axis=1).tolist()\n",
    "\n",
    "print(accuracy_score(ytrue, ypred_blstm))\n",
    "multilabel_confusion_matrix(ytrue, ypred_blstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to synchronously create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_blstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_blstm.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_blstm.save('model_blstm.h5')\n",
    "# Assuming you have a numpy array called 'data'\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
