{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0 ...  0  0  0]\n",
      " [ 0 20  3 ...  0  0  0]\n",
      " [ 0  8 16 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 19  0  0]\n",
      " [ 0  0  0 ...  0 20  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        27\n",
      "           1       0.71      0.87      0.78        23\n",
      "           2       0.84      0.67      0.74        24\n",
      "           3       1.00      1.00      1.00        24\n",
      "           4       0.91      0.88      0.89        24\n",
      "           5       0.92      1.00      0.96        24\n",
      "           6       0.82      0.82      0.82        17\n",
      "           7       0.95      1.00      0.98        21\n",
      "           8       1.00      0.93      0.97        15\n",
      "           9       1.00      0.82      0.90        11\n",
      "          10       0.88      0.88      0.88        25\n",
      "          11       1.00      0.95      0.98        22\n",
      "          12       0.94      1.00      0.97        16\n",
      "          13       1.00      0.91      0.95        22\n",
      "          14       0.96      1.00      0.98        26\n",
      "          15       0.95      1.00      0.98        21\n",
      "          16       0.96      1.00      0.98        24\n",
      "          17       0.90      0.90      0.90        20\n",
      "          18       0.91      0.95      0.93        21\n",
      "          19       1.00      0.94      0.97        16\n",
      "          20       1.00      1.00      1.00        14\n",
      "          21       1.00      1.00      1.00        20\n",
      "          22       1.00      1.00      1.00        14\n",
      "          23       1.00      0.96      0.98        23\n",
      "          24       0.89      0.94      0.92        18\n",
      "          25       0.91      1.00      0.95        21\n",
      "          26       1.00      1.00      1.00        25\n",
      "          27       1.00      1.00      1.00        14\n",
      "          28       1.00      0.95      0.98        21\n",
      "          29       1.00      0.96      0.98        23\n",
      "          30       0.94      0.94      0.94        18\n",
      "          31       0.95      1.00      0.98        21\n",
      "          32       1.00      0.86      0.92        21\n",
      "          33       1.00      1.00      1.00        28\n",
      "          34       1.00      1.00      1.00        21\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       1.00      1.00      1.00        19\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      0.92      0.96        25\n",
      "          39       1.00      1.00      1.00        23\n",
      "          40       0.95      1.00      0.97        19\n",
      "          41       0.95      1.00      0.97        18\n",
      "          42       0.95      1.00      0.97        18\n",
      "          43       1.00      1.00      1.00        21\n",
      "          44       1.00      1.00      1.00        14\n",
      "          45       0.94      1.00      0.97        17\n",
      "          46       1.00      0.95      0.98        22\n",
      "          47       0.92      0.92      0.92        13\n",
      "          48       0.89      1.00      0.94        17\n",
      "          49       1.00      1.00      1.00        19\n",
      "          50       1.00      0.96      0.98        24\n",
      "          51       1.00      1.00      1.00        19\n",
      "          52       1.00      1.00      1.00        17\n",
      "          53       1.00      0.92      0.96        24\n",
      "          54       1.00      1.00      1.00        24\n",
      "          55       1.00      1.00      1.00        19\n",
      "          56       0.94      1.00      0.97        16\n",
      "          57       1.00      1.00      1.00        21\n",
      "          58       0.86      0.92      0.89        13\n",
      "          59       1.00      1.00      1.00        19\n",
      "          60       1.00      1.00      1.00        24\n",
      "          61       0.90      0.90      0.90        21\n",
      "          62       1.00      1.00      1.00        19\n",
      "          63       0.91      1.00      0.95        20\n",
      "          64       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.96      1300\n",
      "   macro avg       0.96      0.96      0.96      1300\n",
      "weighted avg       0.96      0.96      0.96      1300\n",
      "\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  0 ...  0  0  0]\n",
      " [ 0 17  6 ...  0  0  0]\n",
      " [ 0  5 19 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 19  0  0]\n",
      " [ 0  0  0 ...  0 18  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88        27\n",
      "           1       0.77      0.74      0.76        23\n",
      "           2       0.73      0.79      0.76        24\n",
      "           3       1.00      1.00      1.00        24\n",
      "           4       0.91      0.88      0.89        24\n",
      "           5       0.96      1.00      0.98        24\n",
      "           6       0.88      0.82      0.85        17\n",
      "           7       0.95      0.95      0.95        21\n",
      "           8       0.88      0.93      0.90        15\n",
      "           9       1.00      0.91      0.95        11\n",
      "          10       0.89      0.96      0.92        25\n",
      "          11       1.00      0.82      0.90        22\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       0.85      1.00      0.92        22\n",
      "          14       0.96      0.85      0.90        26\n",
      "          15       0.95      0.95      0.95        21\n",
      "          16       0.92      1.00      0.96        24\n",
      "          17       0.86      0.90      0.88        20\n",
      "          18       0.78      1.00      0.88        21\n",
      "          19       1.00      0.88      0.93        16\n",
      "          20       1.00      1.00      1.00        14\n",
      "          21       1.00      0.95      0.97        20\n",
      "          22       0.88      1.00      0.93        14\n",
      "          23       0.92      0.96      0.94        23\n",
      "          24       0.90      1.00      0.95        18\n",
      "          25       0.95      0.95      0.95        21\n",
      "          26       0.96      1.00      0.98        25\n",
      "          27       1.00      1.00      1.00        14\n",
      "          28       1.00      1.00      1.00        21\n",
      "          29       1.00      0.96      0.98        23\n",
      "          30       1.00      1.00      1.00        18\n",
      "          31       1.00      1.00      1.00        21\n",
      "          32       1.00      1.00      1.00        21\n",
      "          33       1.00      1.00      1.00        28\n",
      "          34       1.00      1.00      1.00        21\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       0.95      1.00      0.97        19\n",
      "          37       0.90      1.00      0.95        19\n",
      "          38       1.00      1.00      1.00        25\n",
      "          39       0.96      0.96      0.96        23\n",
      "          40       1.00      1.00      1.00        19\n",
      "          41       1.00      0.94      0.97        18\n",
      "          42       0.95      1.00      0.97        18\n",
      "          43       1.00      0.95      0.98        21\n",
      "          44       1.00      1.00      1.00        14\n",
      "          45       1.00      1.00      1.00        17\n",
      "          46       1.00      0.95      0.98        22\n",
      "          47       1.00      0.92      0.96        13\n",
      "          48       1.00      1.00      1.00        17\n",
      "          49       1.00      1.00      1.00        19\n",
      "          50       1.00      0.96      0.98        24\n",
      "          51       1.00      1.00      1.00        19\n",
      "          52       1.00      1.00      1.00        17\n",
      "          53       1.00      0.92      0.96        24\n",
      "          54       1.00      1.00      1.00        24\n",
      "          55       0.95      1.00      0.97        19\n",
      "          56       1.00      0.94      0.97        16\n",
      "          57       1.00      1.00      1.00        21\n",
      "          58       0.93      1.00      0.96        13\n",
      "          59       1.00      1.00      1.00        19\n",
      "          60       1.00      1.00      1.00        24\n",
      "          61       1.00      0.95      0.98        21\n",
      "          62       0.95      1.00      0.97        19\n",
      "          63       1.00      0.90      0.95        20\n",
      "          64       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.96      1300\n",
      "   macro avg       0.96      0.96      0.96      1300\n",
      "weighted avg       0.96      0.96      0.96      1300\n",
      "\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0  0 ...  0  0  0]\n",
      " [ 0 18  5 ...  0  0  0]\n",
      " [ 0  6 17 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 17  0  0]\n",
      " [ 0  0  0 ...  0 18  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77        27\n",
      "           1       0.72      0.78      0.75        23\n",
      "           2       0.77      0.71      0.74        24\n",
      "           3       1.00      1.00      1.00        24\n",
      "           4       0.81      0.88      0.84        24\n",
      "           5       0.96      1.00      0.98        24\n",
      "           6       0.74      0.82      0.78        17\n",
      "           7       0.95      1.00      0.98        21\n",
      "           8       1.00      0.73      0.85        15\n",
      "           9       0.89      0.73      0.80        11\n",
      "          10       0.96      0.88      0.92        25\n",
      "          11       0.84      0.95      0.89        22\n",
      "          12       0.84      1.00      0.91        16\n",
      "          13       1.00      0.91      0.95        22\n",
      "          14       0.89      0.92      0.91        26\n",
      "          15       0.91      0.95      0.93        21\n",
      "          16       0.96      1.00      0.98        24\n",
      "          17       0.94      0.75      0.83        20\n",
      "          18       0.88      0.71      0.79        21\n",
      "          19       1.00      0.88      0.93        16\n",
      "          20       1.00      0.93      0.96        14\n",
      "          21       0.95      0.95      0.95        20\n",
      "          22       0.87      0.93      0.90        14\n",
      "          23       1.00      0.96      0.98        23\n",
      "          24       0.80      0.89      0.84        18\n",
      "          25       0.91      1.00      0.95        21\n",
      "          26       0.96      0.96      0.96        25\n",
      "          27       0.87      0.93      0.90        14\n",
      "          28       1.00      0.95      0.98        21\n",
      "          29       0.80      0.87      0.83        23\n",
      "          30       0.84      0.89      0.86        18\n",
      "          31       0.95      1.00      0.98        21\n",
      "          32       1.00      0.86      0.92        21\n",
      "          33       1.00      0.86      0.92        28\n",
      "          34       0.90      0.86      0.88        21\n",
      "          35       0.80      1.00      0.89        16\n",
      "          36       0.95      0.95      0.95        19\n",
      "          37       0.90      0.95      0.92        19\n",
      "          38       0.96      0.88      0.92        25\n",
      "          39       1.00      0.65      0.79        23\n",
      "          40       0.86      1.00      0.93        19\n",
      "          41       0.74      0.78      0.76        18\n",
      "          42       0.81      0.94      0.87        18\n",
      "          43       1.00      0.95      0.98        21\n",
      "          44       0.93      0.93      0.93        14\n",
      "          45       0.89      0.94      0.91        17\n",
      "          46       0.90      0.82      0.86        22\n",
      "          47       0.92      0.92      0.92        13\n",
      "          48       1.00      1.00      1.00        17\n",
      "          49       0.95      0.95      0.95        19\n",
      "          50       0.96      0.96      0.96        24\n",
      "          51       0.86      0.95      0.90        19\n",
      "          52       0.89      1.00      0.94        17\n",
      "          53       0.86      0.75      0.80        24\n",
      "          54       1.00      1.00      1.00        24\n",
      "          55       0.90      1.00      0.95        19\n",
      "          56       0.93      0.88      0.90        16\n",
      "          57       1.00      1.00      1.00        21\n",
      "          58       0.80      0.92      0.86        13\n",
      "          59       1.00      1.00      1.00        19\n",
      "          60       0.91      0.88      0.89        24\n",
      "          61       0.84      0.76      0.80        21\n",
      "          62       0.89      0.89      0.89        19\n",
      "          63       0.95      0.90      0.92        20\n",
      "          64       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.90      1300\n",
      "   macro avg       0.91      0.91      0.90      1300\n",
      "weighted avg       0.91      0.90      0.90      1300\n",
      "\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0  0 ...  0  0  0]\n",
      " [ 0 16  5 ...  0  0  0]\n",
      " [ 0  6 16 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 19  0  0]\n",
      " [ 0  0  0 ...  0 19  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        27\n",
      "           1       0.73      0.70      0.71        23\n",
      "           2       0.76      0.67      0.71        24\n",
      "           3       1.00      1.00      1.00        24\n",
      "           4       0.92      0.50      0.65        24\n",
      "           5       1.00      1.00      1.00        24\n",
      "           6       0.73      0.94      0.82        17\n",
      "           7       0.95      0.86      0.90        21\n",
      "           8       1.00      0.87      0.93        15\n",
      "           9       1.00      0.82      0.90        11\n",
      "          10       0.95      0.80      0.87        25\n",
      "          11       0.95      0.95      0.95        22\n",
      "          12       0.89      1.00      0.94        16\n",
      "          13       0.75      0.95      0.84        22\n",
      "          14       0.88      0.81      0.84        26\n",
      "          15       0.95      1.00      0.98        21\n",
      "          16       0.96      0.96      0.96        24\n",
      "          17       0.61      0.95      0.75        20\n",
      "          18       0.86      0.90      0.88        21\n",
      "          19       0.93      0.88      0.90        16\n",
      "          20       1.00      1.00      1.00        14\n",
      "          21       0.94      0.80      0.86        20\n",
      "          22       0.72      0.93      0.81        14\n",
      "          23       0.96      0.96      0.96        23\n",
      "          24       0.82      1.00      0.90        18\n",
      "          25       0.95      1.00      0.98        21\n",
      "          26       0.96      1.00      0.98        25\n",
      "          27       1.00      0.86      0.92        14\n",
      "          28       0.95      0.86      0.90        21\n",
      "          29       1.00      0.91      0.95        23\n",
      "          30       0.89      0.94      0.92        18\n",
      "          31       0.95      0.90      0.93        21\n",
      "          32       0.95      0.95      0.95        21\n",
      "          33       1.00      1.00      1.00        28\n",
      "          34       0.95      0.86      0.90        21\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       0.95      1.00      0.97        19\n",
      "          37       0.95      0.95      0.95        19\n",
      "          38       1.00      0.88      0.94        25\n",
      "          39       0.88      0.91      0.89        23\n",
      "          40       0.86      1.00      0.93        19\n",
      "          41       1.00      0.89      0.94        18\n",
      "          42       0.86      1.00      0.92        18\n",
      "          43       0.95      0.95      0.95        21\n",
      "          44       1.00      1.00      1.00        14\n",
      "          45       0.84      0.94      0.89        17\n",
      "          46       1.00      0.91      0.95        22\n",
      "          47       0.81      1.00      0.90        13\n",
      "          48       1.00      0.94      0.97        17\n",
      "          49       0.90      0.95      0.92        19\n",
      "          50       1.00      0.88      0.93        24\n",
      "          51       0.89      0.84      0.86        19\n",
      "          52       1.00      1.00      1.00        17\n",
      "          53       0.88      0.92      0.90        24\n",
      "          54       0.95      0.88      0.91        24\n",
      "          55       0.95      1.00      0.97        19\n",
      "          56       0.88      0.88      0.88        16\n",
      "          57       1.00      0.90      0.95        21\n",
      "          58       0.92      0.92      0.92        13\n",
      "          59       1.00      1.00      1.00        19\n",
      "          60       0.92      1.00      0.96        24\n",
      "          61       0.86      0.86      0.86        21\n",
      "          62       1.00      1.00      1.00        19\n",
      "          63       0.86      0.95      0.90        20\n",
      "          64       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.91      1300\n",
      "   macro avg       0.92      0.92      0.92      1300\n",
      "weighted avg       0.92      0.91      0.91      1300\n",
      "\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25  0  0 ...  0  0  0]\n",
      " [ 0 10 11 ...  0  0  0]\n",
      " [ 0  4 19 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 18  0  0]\n",
      " [ 0  0  0 ...  0 18  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89        27\n",
      "           1       0.71      0.43      0.54        23\n",
      "           2       0.63      0.79      0.70        24\n",
      "           3       1.00      1.00      1.00        24\n",
      "           4       0.72      0.88      0.79        24\n",
      "           5       1.00      1.00      1.00        24\n",
      "           6       0.75      0.88      0.81        17\n",
      "           7       0.88      1.00      0.93        21\n",
      "           8       0.93      0.93      0.93        15\n",
      "           9       1.00      1.00      1.00        11\n",
      "          10       0.88      0.84      0.86        25\n",
      "          11       0.90      0.86      0.88        22\n",
      "          12       0.94      1.00      0.97        16\n",
      "          13       1.00      0.86      0.93        22\n",
      "          14       0.86      0.96      0.91        26\n",
      "          15       0.95      0.95      0.95        21\n",
      "          16       1.00      1.00      1.00        24\n",
      "          17       0.80      0.60      0.69        20\n",
      "          18       0.91      0.95      0.93        21\n",
      "          19       1.00      0.81      0.90        16\n",
      "          20       1.00      1.00      1.00        14\n",
      "          21       0.95      0.95      0.95        20\n",
      "          22       0.88      1.00      0.93        14\n",
      "          23       1.00      0.91      0.95        23\n",
      "          24       0.89      0.89      0.89        18\n",
      "          25       0.95      1.00      0.98        21\n",
      "          26       0.96      1.00      0.98        25\n",
      "          27       0.86      0.86      0.86        14\n",
      "          28       1.00      1.00      1.00        21\n",
      "          29       1.00      0.87      0.93        23\n",
      "          30       1.00      0.89      0.94        18\n",
      "          31       0.95      1.00      0.98        21\n",
      "          32       1.00      0.95      0.98        21\n",
      "          33       1.00      1.00      1.00        28\n",
      "          34       0.95      0.90      0.93        21\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       0.95      1.00      0.97        19\n",
      "          37       0.95      0.95      0.95        19\n",
      "          38       0.96      0.96      0.96        25\n",
      "          39       0.91      0.91      0.91        23\n",
      "          40       1.00      1.00      1.00        19\n",
      "          41       0.89      0.94      0.92        18\n",
      "          42       0.90      1.00      0.95        18\n",
      "          43       1.00      0.95      0.98        21\n",
      "          44       1.00      1.00      1.00        14\n",
      "          45       0.94      1.00      0.97        17\n",
      "          46       1.00      0.95      0.98        22\n",
      "          47       0.92      0.92      0.92        13\n",
      "          48       1.00      1.00      1.00        17\n",
      "          49       0.90      0.95      0.92        19\n",
      "          50       1.00      1.00      1.00        24\n",
      "          51       0.89      0.84      0.86        19\n",
      "          52       1.00      1.00      1.00        17\n",
      "          53       1.00      0.88      0.93        24\n",
      "          54       1.00      1.00      1.00        24\n",
      "          55       1.00      0.89      0.94        19\n",
      "          56       0.94      1.00      0.97        16\n",
      "          57       0.91      1.00      0.95        21\n",
      "          58       0.79      0.85      0.81        13\n",
      "          59       1.00      1.00      1.00        19\n",
      "          60       0.96      0.96      0.96        24\n",
      "          61       0.90      0.90      0.90        21\n",
      "          62       0.95      0.95      0.95        19\n",
      "          63       0.95      0.90      0.92        20\n",
      "          64       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.93      1300\n",
      "   macro avg       0.93      0.93      0.93      1300\n",
      "weighted avg       0.93      0.93      0.93      1300\n",
      "\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "[[23  0  0 ...  0  0  0]\n",
      " [ 0 19  3 ...  0  0  0]\n",
      " [ 0 14  6 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 19  0  0]\n",
      " [ 0  0  0 ...  0 18  0]\n",
      " [ 0  0  0 ...  0  0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82        27\n",
      "           1       0.54      0.83      0.66        23\n",
      "           2       0.55      0.25      0.34        24\n",
      "           3       1.00      0.96      0.98        24\n",
      "           4       0.89      0.71      0.79        24\n",
      "           5       0.93      0.58      0.72        24\n",
      "           6       0.74      0.82      0.78        17\n",
      "           7       0.84      1.00      0.91        21\n",
      "           8       0.82      0.93      0.88        15\n",
      "           9       0.56      0.82      0.67        11\n",
      "          10       0.95      0.84      0.89        25\n",
      "          11       0.67      0.73      0.70        22\n",
      "          12       0.88      0.94      0.91        16\n",
      "          13       0.81      0.95      0.88        22\n",
      "          14       0.88      0.85      0.86        26\n",
      "          15       0.84      1.00      0.91        21\n",
      "          16       0.92      1.00      0.96        24\n",
      "          17       0.75      0.90      0.82        20\n",
      "          18       0.88      1.00      0.93        21\n",
      "          19       0.75      0.94      0.83        16\n",
      "          20       0.70      1.00      0.82        14\n",
      "          21       0.86      0.90      0.88        20\n",
      "          22       0.83      0.71      0.77        14\n",
      "          23       0.91      0.87      0.89        23\n",
      "          24       0.71      0.94      0.81        18\n",
      "          25       1.00      0.95      0.98        21\n",
      "          26       0.96      0.88      0.92        25\n",
      "          27       1.00      0.86      0.92        14\n",
      "          28       1.00      0.71      0.83        21\n",
      "          29       0.67      0.78      0.72        23\n",
      "          30       0.94      0.94      0.94        18\n",
      "          31       1.00      1.00      1.00        21\n",
      "          32       1.00      0.76      0.86        21\n",
      "          33       0.97      1.00      0.98        28\n",
      "          34       0.90      0.90      0.90        21\n",
      "          35       1.00      0.94      0.97        16\n",
      "          36       0.90      1.00      0.95        19\n",
      "          37       1.00      0.79      0.88        19\n",
      "          38       0.77      0.80      0.78        25\n",
      "          39       1.00      1.00      1.00        23\n",
      "          40       0.95      0.95      0.95        19\n",
      "          41       0.90      0.50      0.64        18\n",
      "          42       0.90      1.00      0.95        18\n",
      "          43       0.95      0.95      0.95        21\n",
      "          44       1.00      1.00      1.00        14\n",
      "          45       0.79      0.88      0.83        17\n",
      "          46       1.00      0.86      0.93        22\n",
      "          47       1.00      0.92      0.96        13\n",
      "          48       0.94      1.00      0.97        17\n",
      "          49       0.89      0.84      0.86        19\n",
      "          50       1.00      0.79      0.88        24\n",
      "          51       1.00      0.74      0.85        19\n",
      "          52       1.00      1.00      1.00        17\n",
      "          53       0.95      0.79      0.86        24\n",
      "          54       1.00      0.96      0.98        24\n",
      "          55       1.00      1.00      1.00        19\n",
      "          56       0.75      0.94      0.83        16\n",
      "          57       1.00      0.95      0.98        21\n",
      "          58       0.91      0.77      0.83        13\n",
      "          59       1.00      1.00      1.00        19\n",
      "          60       0.89      1.00      0.94        24\n",
      "          61       0.94      0.81      0.87        21\n",
      "          62       0.83      1.00      0.90        19\n",
      "          63       0.82      0.90      0.86        20\n",
      "          64       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.88      1300\n",
      "   macro avg       0.89      0.88      0.88      1300\n",
      "weighted avg       0.89      0.88      0.87      1300\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScores by model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xticks(x)\n\u001b[1;32m---> 56\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_xticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m ax\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     59\u001b[0m fig\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axes\\_base.py:73\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\_api\\deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     warn_deprecated(\n\u001b[0;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\axis.py:2025\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[0;32m   2022\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2025\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2026\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2029\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2030\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[0;32m   2031\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (2)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of model filenames\n",
    "model_filenames = ['../actions/actions_cnn.h5', '../actions/actions_double_gru.h5', '../actions/actions_doubleGru_lstm.h5', \n",
    "                   '../actions/actions_lstm_gru.h5', '../actions/actions_triple_lstm.h5', '../actions/actions_gru_lstm.h5']\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "X = np.load('../sequences_augmented.npy')\n",
    "y = np.load('../labels_augmented.npy')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load each model, make predictions, and calculate metrics\n",
    "for filename in model_filenames:\n",
    "    # Load the model\n",
    "    model = load_model(filename)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    # Store metrics\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Plot metrics\n",
    "x = np.arange(len(model_filenames))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, precisions, width, label='Precision')\n",
    "rects2 = ax.bar(x, recalls, width, label='Recall')\n",
    "rects3 = ax.bar(x + width, f1_scores, width, label='F1 Score')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_filenames, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
